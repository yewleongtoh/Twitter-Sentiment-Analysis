{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9911ca30",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc10aa",
   "metadata": {},
   "source": [
    "In this project, we aim to perform sentiment analysis on tweets related to disasters, utilizing natural language processing techniques and machine learning algorithms. Our goal is to accurately classify tweets as either disaster-related or non-disaster-related based on their content and sentiments expressed.\n",
    "\n",
    "The dataset used for this project is sourced from https://www.kaggle.com/code/pavansanagapati/knowledge-graph-nlp-tutorial-bert-spacy-nltk/data. This dataset contains a collection of tweets, each labeled as either \"disaster\" or \"non-disaster.\"\n",
    "\n",
    "Twitter serves as a significant platform for real-time information dissemination during natural disasters and emergencies. However, amid the influx of tweets, it becomes challenging for human operators to quickly discern which tweets are genuinely relevant to disasters. Therefore, an automated system that can efficiently identify and classify disaster-related tweets can be invaluable for emergency response, news agencies, and public awareness.\n",
    "\n",
    "In this project, we will explore various natural language processing techniques, including tokenization, stemming or lemmatization, and feature extraction. We will employ machine learning models, with a particular focus on Naive Bayes, to classify tweets based on their content and sentiment, determining whether they pertain to a disaster or not. Additionally, we will evaluate the model's performance using appropriate metrics and aim to achieve high accuracy in classifying disaster-related tweets to aid in crisis management and public safety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f050ae14",
   "metadata": {},
   "source": [
    "## 1. Download Corpora & Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f24180",
   "metadata": {},
   "source": [
    "Download the Gutenberg corpus from NLTK, which contains diverse literary texts, enabling the enhancement of sentiment analysis models through training on a wide range of writing styles and historical linguistic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dcedc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('gutenberg')\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b9ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gutenberg Project\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310060e",
   "metadata": {},
   "source": [
    "We selected **Bryant-stories.txt** from the Gutenberg corpus as the text file to explore and analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0caf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stories to Tell to Children by Sara Cone Bryant 1918] \r\n",
      "\r\n",
      "\r\n",
      "TWO LITTLE RIDDLES IN RHYME\r\n",
      "\r\n",
      "\r\n",
      "     There's a garden that I ken,\r\n",
      "     Full of little gentlemen;\r\n",
      "     Little caps of blue they wear,\r\n",
      "     And green ribbons, very fair.\r\n",
      "           (Flax.)\r\n",
      "\r\n",
      "     From house to house he goes,\r\n",
      "     A messenger small and slight,\r\n",
      "     And whether it rains or snows,\r\n",
      "     He sleeps outside in the night.\r\n",
      "           (The path.)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "THE LITTLE YELLOW TULIP\r\n",
      "\r\n",
      "\r\n",
      "Once there was a little yellow Tulip, and she lived down in a little\r\n",
      "dark house under the ground. One day she was sitting there, all by\r\n",
      "herself, and it was very still. Suddenly, she heard a little _tap, tap,\r\n",
      "tap_, at the door.\r\n",
      "\r\n",
      "\"Who is that?\" she said.\r\n",
      "\r\n",
      "\"It's the Rain, and I want to come in,\" said a soft, sad, little voice.\r\n",
      "\r\n",
      "\"No, you can't come in,\" the little Tulip said.\r\n",
      "\r\n",
      "By and by she heard another little _tap, tap, tap_ on the window-pane.\r\n",
      "\r\n",
      "\"Who is there?\" she said.\r\n",
      "\r\n",
      "The same soft little voice answered, \"It's the \n"
     ]
    }
   ],
   "source": [
    "text = gutenberg.raw('bryant-stories.txt')\n",
    "\n",
    "# print out small chunk of bryant-stories.txt\n",
    "print(text.strip()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59acd994",
   "metadata": {},
   "source": [
    "**Bryant-stories.txt** appears to be a compilation of poems, stories written in straightforward language, and even includes dialogues, offering a diverse collection of text types for analysis in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596dfe1c",
   "metadata": {},
   "source": [
    "## 2. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42122d0",
   "metadata": {},
   "source": [
    "Tokenization is about breaking a paragraph into smaller meaningful units. In this case, we have two types:\n",
    "\n",
    "- **Sentence tokenization:** It involves dividing a paragraph into individual sentences. \n",
    "- **Word tokenization:** It takes each sentence and breaks it down further into individual words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315307f",
   "metadata": {},
   "source": [
    "### 2.1 Step 1 - Cleaning: Remove Title, Chapter, Author, Line separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be190e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove title\n",
    "text = text.replace(\"[Stories to Tell to Children by Sara Cone Bryant 1918]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1323133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove poem\n",
    "text = text.strip()[402:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997342e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line separation\n",
    "text = text.replace(\"\\r\\n\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d884a18e",
   "metadata": {},
   "source": [
    "Lets take a look at the first 10 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b6174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tOnce there was a little yellow Tulip, and she lived down in a little dark house under the ground\n",
      "1:\t One day she was sitting there, all by herself, and it was very still\n",
      "2:\t Suddenly, she heard a little _tap, tap, tap_, at the door\n",
      "3:\t  \"Who is that?\" she said\n",
      "4:\t  \"It's the Rain, and I want to come in,\" said a soft, sad, little voice\n",
      "5:\t  \"No, you can't come in,\" the little Tulip said\n",
      "6:\t  By and by she heard another little _tap, tap, tap_ on the window-pane\n",
      "7:\t  \"Who is there?\" she said\n",
      "8:\t  The same soft little voice answered, \"It's the Rain, and I want to come in!\"  \"No, you can't come in,\" said the little Tulip\n",
      "9:\t  Then it was very still for a long time\n",
      "10:\t At last, there came a little rustling, whispering sound, all round the window: _rustle, whisper, whisper_\n",
      "11:\t  \"Who is there?\" said the little Tulip\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(text.split('.')):\n",
    "    if len(line) > 0:\n",
    "        print(str(i) + ':\\t' + line)\n",
    "    if i > 10: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf088d99",
   "metadata": {},
   "source": [
    "### 2.2 Step 2 - Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46b6efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'there', 'was', 'a', 'little', 'yellow', 'tulip', ',', 'and', 'she']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and lowercase\n",
    "tokenized_lowered = list(map(str.lower, word_tokenize(text)))\n",
    "print(tokenized_lowered[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd07762",
   "metadata": {},
   "source": [
    "### 2.3 Step 3 - Define Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e31f713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"needn't\", 'we', 'them', 'from', 'just', 'can', 'don', 'themselves', 'when', 'o', 'below', 'yours', 've', \"you'll\", 'haven', \"wasn't\", 'a', 'there', 'own', 't', 'same', \"shan't\", 'does', \"haven't\", 'was', 'over', 'only', \"you'd\", 'off', 'our', 'isn', 'then', 'yourself', 'about', 'whom', 'all', 'each', 'down', 'mustn', 'having', 'its', 's', 'myself', 'because', \"wouldn't\", 'won', 'she', \"that'll\", 'doing', 'should', 'aren', 'couldn', \"hasn't\", 'any', 'for', 'it', \"don't\", 'her', 'until', 'to', 'again', 'weren', 'some', 'you', 'an', 'shan', 'had', 'more', 'hadn', 'ourselves', 'theirs', 'am', 'not', 'doesn', 'while', \"you're\", 'most', \"didn't\", \"doesn't\", 'wasn', \"aren't\", 'this', 'after', 'he', 'yourselves', 'himself', 'but', 'now', 'the', 'both', 'his', \"should've\", 'needn', 'itself', 'who', 'herself', 'their', 'above', 'than', 're', \"she's\", \"couldn't\", 'what', 'wouldn', 'other', 'here', 'or', 'as', 'few', 'ain', 'where', 'of', 'ours', 'mightn', 'in', 'very', \"won't\", 'were', \"you've\", 'why', 'too', 'by', 'under', \"mustn't\", 'did', 'is', 'once', 'your', \"hadn't\", \"it's\", 'didn', 'my', 'such', 'and', 'so', 'me', 'those', 'are', \"shouldn't\", 'hasn', 'further', 'him', 'that', 'against', 'on', 'nor', 'which', 'before', 'no', 'shouldn', 'out', 'how', 'if', 'these', 'ma', 'with', 'been', 'll', 'be', 'up', 'i', 'at', \"weren't\", 'during', 'd', 'between', 'y', 'hers', 'into', 'they', 'have', 'm', 'do', 'being', 'will', \"mightn't\", \"isn't\", 'through', 'has'}\n"
     ]
    }
   ],
   "source": [
    "# Stopwords for English\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "# Print the example of stopwords from NLTK\n",
    "print(stopwords_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be715c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['little', 'yellow', 'tulip', ',', 'lived', 'little', 'dark', 'house', 'ground', '.']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in tokenized_lowered if word not in stopwords_en][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa38f0c",
   "metadata": {},
   "source": [
    "### 2.4 Step 4 - Define Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba17365",
   "metadata": {},
   "source": [
    "Let's take a look at what is included in the punctuation provided by library `string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4be5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c74c24",
   "metadata": {},
   "source": [
    "### 2.5 Step 5 - Remove Stopwords and Punctuation from Tokenized words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c49bffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the stopwords with punctuation\n",
    "stopwords_en_withpunct = stopwords_en.union(set(punctuation))\n",
    "\n",
    "# Remove both from Tokenized word\n",
    "tokenized_lowered_noStop_noPunc = [word for word in tokenized_lowered if word not in stopwords_en_withpunct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fef19758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['little',\n",
       " 'yellow',\n",
       " 'tulip',\n",
       " 'lived',\n",
       " 'little',\n",
       " 'dark',\n",
       " 'house',\n",
       " 'ground',\n",
       " 'one',\n",
       " 'day',\n",
       " 'sitting',\n",
       " 'still',\n",
       " 'suddenly',\n",
       " 'heard',\n",
       " 'little',\n",
       " '_tap',\n",
       " 'tap',\n",
       " 'tap_',\n",
       " 'door',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " '``',\n",
       " \"'s\",\n",
       " 'rain',\n",
       " 'want',\n",
       " 'come',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'soft',\n",
       " 'sad',\n",
       " 'little',\n",
       " 'voice',\n",
       " '``',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'come',\n",
       " \"''\",\n",
       " 'little',\n",
       " 'tulip',\n",
       " 'said',\n",
       " 'heard',\n",
       " 'another',\n",
       " 'little',\n",
       " '_tap',\n",
       " 'tap',\n",
       " 'tap_',\n",
       " 'window-pane',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'soft',\n",
       " 'little',\n",
       " 'voice',\n",
       " 'answered',\n",
       " '``',\n",
       " \"'s\",\n",
       " 'rain',\n",
       " 'want',\n",
       " 'come',\n",
       " \"''\",\n",
       " '``',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'come',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'tulip',\n",
       " 'still',\n",
       " 'long',\n",
       " 'time',\n",
       " 'last',\n",
       " 'came',\n",
       " 'little',\n",
       " 'rustling',\n",
       " 'whispering',\n",
       " 'sound',\n",
       " 'round',\n",
       " 'window',\n",
       " '_rustle',\n",
       " 'whisper',\n",
       " 'whisper_',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'tulip',\n",
       " '``',\n",
       " \"'s\",\n",
       " 'sunshine',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'soft',\n",
       " 'cheery',\n",
       " 'voice',\n",
       " '``',\n",
       " 'want',\n",
       " 'come',\n",
       " \"''\",\n",
       " '``',\n",
       " 'n',\n",
       " '--',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'tulip',\n",
       " '``',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'come',\n",
       " \"''\",\n",
       " 'sat',\n",
       " 'still',\n",
       " 'pretty',\n",
       " 'soon',\n",
       " 'heard',\n",
       " 'sweet',\n",
       " 'little',\n",
       " 'rustling',\n",
       " 'noise',\n",
       " 'keyhole',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " '``',\n",
       " \"'s\",\n",
       " 'sunshine',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'cheery',\n",
       " 'little',\n",
       " 'voice',\n",
       " '``',\n",
       " 'want',\n",
       " 'come',\n",
       " 'want',\n",
       " 'come',\n",
       " \"''\",\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'tulip',\n",
       " '``',\n",
       " 'come',\n",
       " \"''\",\n",
       " 'sat',\n",
       " 'still',\n",
       " 'heard',\n",
       " '_tap',\n",
       " 'tap',\n",
       " 'tap_',\n",
       " '_rustle',\n",
       " 'whisper',\n",
       " 'rustle_',\n",
       " 'window-pane',\n",
       " 'door',\n",
       " 'keyhole',\n",
       " '``',\n",
       " '_who',\n",
       " \"''\",\n",
       " 'said',\n",
       " '``',\n",
       " \"'s\",\n",
       " 'rain',\n",
       " 'sun',\n",
       " 'rain',\n",
       " 'sun',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'two',\n",
       " 'little',\n",
       " 'voices',\n",
       " 'together',\n",
       " '``',\n",
       " 'want',\n",
       " 'come',\n",
       " 'want',\n",
       " 'come',\n",
       " 'want',\n",
       " 'come',\n",
       " \"''\",\n",
       " '``',\n",
       " 'dear',\n",
       " 'dear',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'tulip',\n",
       " '``',\n",
       " 'two',\n",
       " \"s'pose\",\n",
       " 'shall',\n",
       " 'let',\n",
       " \"''\",\n",
       " 'opened',\n",
       " 'door',\n",
       " 'little',\n",
       " 'wee',\n",
       " 'crack',\n",
       " 'came',\n",
       " 'one',\n",
       " 'took',\n",
       " 'one',\n",
       " 'little',\n",
       " 'hands',\n",
       " 'took',\n",
       " 'little',\n",
       " 'hand',\n",
       " 'ran',\n",
       " 'ran',\n",
       " 'ran',\n",
       " 'right',\n",
       " 'top',\n",
       " 'ground',\n",
       " 'said',\n",
       " '--',\n",
       " '``',\n",
       " 'poke',\n",
       " 'head',\n",
       " \"''\",\n",
       " 'poked',\n",
       " 'head',\n",
       " 'midst',\n",
       " 'beautiful',\n",
       " 'garden',\n",
       " 'early',\n",
       " 'springtime',\n",
       " 'flowers',\n",
       " 'seen',\n",
       " 'birds',\n",
       " 'sing',\n",
       " 'sun',\n",
       " 'shine',\n",
       " 'upon',\n",
       " 'pretty',\n",
       " 'yellow',\n",
       " 'head',\n",
       " 'pleased',\n",
       " 'children',\n",
       " 'exclaimed',\n",
       " 'pleasure',\n",
       " 'knew',\n",
       " 'beautiful',\n",
       " 'spring',\n",
       " 'come',\n",
       " 'cock-a-doo-dle-doo',\n",
       " 'little',\n",
       " 'boy',\n",
       " 'made',\n",
       " 'story',\n",
       " '``',\n",
       " 'head',\n",
       " \"''\",\n",
       " 'told',\n",
       " 'papa',\n",
       " 'think',\n",
       " 'littlest',\n",
       " 'ones',\n",
       " 'like',\n",
       " 'upon',\n",
       " 'time',\n",
       " 'little',\n",
       " 'boy',\n",
       " 'wanted',\n",
       " 'cock-a-doo-dle-doo',\n",
       " 'cock-a-doo-dle-doo',\n",
       " 'wanted',\n",
       " 'fly',\n",
       " 'sky',\n",
       " 'fly',\n",
       " 'sky',\n",
       " 'wanted',\n",
       " 'get',\n",
       " 'wings',\n",
       " 'tail',\n",
       " 'get',\n",
       " 'wings',\n",
       " 'tail',\n",
       " 'cloud',\n",
       " 'one',\n",
       " 'hot',\n",
       " 'summer',\n",
       " 'morning',\n",
       " 'little',\n",
       " 'cloud',\n",
       " 'rose',\n",
       " 'sea',\n",
       " 'floated',\n",
       " 'lightly',\n",
       " 'happily',\n",
       " 'across',\n",
       " 'blue',\n",
       " 'sky',\n",
       " 'far',\n",
       " 'lay',\n",
       " 'earth',\n",
       " 'brown',\n",
       " 'dry',\n",
       " 'desolate',\n",
       " 'drought',\n",
       " 'little',\n",
       " 'cloud',\n",
       " 'could',\n",
       " 'see',\n",
       " 'poor',\n",
       " 'people',\n",
       " 'earth',\n",
       " 'working',\n",
       " 'suffering',\n",
       " 'hot',\n",
       " 'fields',\n",
       " 'floated',\n",
       " 'morning',\n",
       " 'breeze',\n",
       " 'hither',\n",
       " 'thither',\n",
       " 'without',\n",
       " 'care',\n",
       " '``',\n",
       " 'oh',\n",
       " 'could',\n",
       " 'help',\n",
       " 'poor',\n",
       " 'people',\n",
       " \"''\",\n",
       " 'thought',\n",
       " '``',\n",
       " 'could',\n",
       " 'make',\n",
       " 'work',\n",
       " 'easier',\n",
       " 'give',\n",
       " 'hungry',\n",
       " 'ones',\n",
       " 'food',\n",
       " 'thirsty',\n",
       " 'drink',\n",
       " \"''\",\n",
       " 'day',\n",
       " 'passed',\n",
       " 'cloud',\n",
       " 'became',\n",
       " 'larger',\n",
       " 'wish',\n",
       " 'something',\n",
       " 'people',\n",
       " 'earth',\n",
       " 'ever',\n",
       " 'greater',\n",
       " 'heart',\n",
       " 'earth',\n",
       " 'grew',\n",
       " 'hotter',\n",
       " 'hotter',\n",
       " 'sun',\n",
       " 'burned',\n",
       " 'fiercely',\n",
       " 'people',\n",
       " 'fainting',\n",
       " 'rays',\n",
       " 'seemed',\n",
       " 'must',\n",
       " 'die',\n",
       " 'heat',\n",
       " 'yet',\n",
       " 'obliged',\n",
       " 'go',\n",
       " 'work',\n",
       " 'poor',\n",
       " 'sometimes',\n",
       " 'stood',\n",
       " 'looked',\n",
       " 'cloud',\n",
       " 'praying',\n",
       " 'saying',\n",
       " '``',\n",
       " 'ah',\n",
       " 'could',\n",
       " 'help',\n",
       " 'us',\n",
       " \"''\",\n",
       " '``',\n",
       " 'help',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'cloud',\n",
       " 'began',\n",
       " 'sink',\n",
       " 'softly',\n",
       " 'toward',\n",
       " 'earth',\n",
       " 'suddenly',\n",
       " 'floated',\n",
       " 'remembered',\n",
       " 'something',\n",
       " 'told',\n",
       " 'tiny',\n",
       " 'cloud-child',\n",
       " 'lap',\n",
       " 'mother',\n",
       " 'ocean',\n",
       " 'whispered',\n",
       " 'clouds',\n",
       " 'go',\n",
       " 'near',\n",
       " 'earth',\n",
       " 'die',\n",
       " 'remembered',\n",
       " 'held',\n",
       " 'sinking',\n",
       " 'swayed',\n",
       " 'breeze',\n",
       " 'thinking',\n",
       " '--',\n",
       " 'thinking',\n",
       " 'last',\n",
       " 'stood',\n",
       " 'quite',\n",
       " 'still',\n",
       " 'spoke',\n",
       " 'boldly',\n",
       " 'proudly',\n",
       " 'said',\n",
       " '``',\n",
       " 'men',\n",
       " 'earth',\n",
       " 'help',\n",
       " 'come',\n",
       " 'may',\n",
       " \"''\",\n",
       " 'thought',\n",
       " 'made',\n",
       " 'suddenly',\n",
       " 'marvellously',\n",
       " 'big',\n",
       " 'strong',\n",
       " 'powerful',\n",
       " 'never',\n",
       " 'dreamed',\n",
       " 'could',\n",
       " 'big',\n",
       " 'like',\n",
       " 'mighty',\n",
       " 'angel',\n",
       " 'blessing',\n",
       " 'stood',\n",
       " 'earth',\n",
       " 'lifted',\n",
       " 'head',\n",
       " 'spread',\n",
       " 'wings',\n",
       " 'far',\n",
       " 'fields',\n",
       " 'woods',\n",
       " 'great',\n",
       " 'majestic',\n",
       " 'men',\n",
       " 'animals',\n",
       " 'awe-struck',\n",
       " 'sight',\n",
       " 'trees',\n",
       " 'grasses',\n",
       " 'bowed',\n",
       " 'yet',\n",
       " 'earth-creatures',\n",
       " 'felt',\n",
       " 'meant',\n",
       " 'well',\n",
       " '``',\n",
       " 'yes',\n",
       " 'help',\n",
       " \"''\",\n",
       " 'cried',\n",
       " 'cloud',\n",
       " '``',\n",
       " 'take',\n",
       " 'give',\n",
       " 'life',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'words',\n",
       " 'wonderful',\n",
       " 'light',\n",
       " 'glowed',\n",
       " 'heart',\n",
       " 'sound',\n",
       " 'thunder',\n",
       " 'rolled',\n",
       " 'sky',\n",
       " 'love',\n",
       " 'greater',\n",
       " 'words',\n",
       " 'tell',\n",
       " 'filled',\n",
       " 'cloud',\n",
       " 'close',\n",
       " 'earth',\n",
       " 'swept',\n",
       " 'gave',\n",
       " 'life',\n",
       " 'blessed',\n",
       " 'healing',\n",
       " 'shower',\n",
       " 'rain',\n",
       " 'rain',\n",
       " 'cloud',\n",
       " \"'s\",\n",
       " 'great',\n",
       " 'deed',\n",
       " 'death',\n",
       " 'also',\n",
       " 'glory',\n",
       " 'whole',\n",
       " 'country-side',\n",
       " 'far',\n",
       " 'rain',\n",
       " 'fell',\n",
       " 'lovely',\n",
       " 'rainbow',\n",
       " 'sprang',\n",
       " 'arch',\n",
       " 'brightest',\n",
       " 'rays',\n",
       " 'heaven',\n",
       " 'made',\n",
       " 'colours',\n",
       " 'last',\n",
       " 'greeting',\n",
       " 'love',\n",
       " 'great',\n",
       " 'sacrificed',\n",
       " 'soon',\n",
       " 'gone',\n",
       " 'long',\n",
       " 'long',\n",
       " 'afterward',\n",
       " 'men',\n",
       " 'animals',\n",
       " 'saved',\n",
       " 'cloud',\n",
       " 'kept',\n",
       " 'blessing',\n",
       " 'hearts',\n",
       " 'little',\n",
       " 'red',\n",
       " 'hen',\n",
       " 'little',\n",
       " 'red',\n",
       " 'hen',\n",
       " 'farmyard',\n",
       " 'chickens',\n",
       " 'found',\n",
       " 'grain',\n",
       " 'wheat',\n",
       " '``',\n",
       " 'plant',\n",
       " 'wheat',\n",
       " \"''\",\n",
       " 'said',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'goose',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'duck',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'red',\n",
       " 'hen',\n",
       " 'planted',\n",
       " 'grain',\n",
       " 'wheat',\n",
       " 'wheat',\n",
       " 'ripe',\n",
       " 'said',\n",
       " '``',\n",
       " 'take',\n",
       " 'wheat',\n",
       " 'mill',\n",
       " \"''\",\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'goose',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'duck',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'red',\n",
       " 'hen',\n",
       " 'took',\n",
       " 'wheat',\n",
       " 'mill',\n",
       " 'brought',\n",
       " 'flour',\n",
       " 'home',\n",
       " 'said',\n",
       " '``',\n",
       " 'make',\n",
       " 'bread',\n",
       " 'flour',\n",
       " \"''\",\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'goose',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'duck',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'red',\n",
       " 'hen',\n",
       " 'bread',\n",
       " 'baked',\n",
       " 'said',\n",
       " '``',\n",
       " 'eat',\n",
       " 'bread',\n",
       " \"''\",\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'goose',\n",
       " '``',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'duck',\n",
       " '``',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " \"''\",\n",
       " 'said',\n",
       " 'little',\n",
       " 'red',\n",
       " 'hen',\n",
       " '``',\n",
       " 'shall',\n",
       " 'eat',\n",
       " 'cluck',\n",
       " 'cluck',\n",
       " \"''\",\n",
       " 'called',\n",
       " 'chickens',\n",
       " 'help',\n",
       " 'gingerbread',\n",
       " 'man',\n",
       " 'upon',\n",
       " 'time',\n",
       " 'little',\n",
       " 'old',\n",
       " 'woman',\n",
       " 'little',\n",
       " 'old',\n",
       " 'man',\n",
       " 'lived',\n",
       " 'alone',\n",
       " 'little',\n",
       " 'old',\n",
       " 'house',\n",
       " \"n't\",\n",
       " 'little',\n",
       " 'girls',\n",
       " 'little',\n",
       " 'boys',\n",
       " 'one',\n",
       " 'day',\n",
       " 'little',\n",
       " 'old',\n",
       " 'woman',\n",
       " 'made',\n",
       " 'boy',\n",
       " 'gingerbread',\n",
       " 'made',\n",
       " 'chocolate',\n",
       " 'jacket',\n",
       " 'put',\n",
       " 'raisins',\n",
       " 'buttons',\n",
       " 'eyes',\n",
       " 'made',\n",
       " 'fine',\n",
       " 'fat',\n",
       " 'currants',\n",
       " 'mouth',\n",
       " 'made',\n",
       " 'rose-coloured',\n",
       " 'sugar',\n",
       " 'gay',\n",
       " 'little',\n",
       " 'cap',\n",
       " 'orange',\n",
       " 'sugar-candy',\n",
       " 'little',\n",
       " 'old',\n",
       " 'woman',\n",
       " 'rolled',\n",
       " 'dressed',\n",
       " 'pinched',\n",
       " 'gingerbread',\n",
       " 'shoes',\n",
       " 'shape',\n",
       " 'put',\n",
       " 'pan',\n",
       " 'put',\n",
       " 'pan',\n",
       " 'oven',\n",
       " 'shut',\n",
       " 'door',\n",
       " 'thought',\n",
       " '``',\n",
       " 'shall',\n",
       " 'little',\n",
       " 'boy',\n",
       " \"''\",\n",
       " 'time',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'done',\n",
       " 'opened',\n",
       " 'oven',\n",
       " 'door',\n",
       " 'pulled',\n",
       " 'pan',\n",
       " 'jumped',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'floor',\n",
       " 'away',\n",
       " 'ran',\n",
       " 'door',\n",
       " 'street',\n",
       " 'little',\n",
       " 'old',\n",
       " 'woman',\n",
       " 'little',\n",
       " 'old',\n",
       " 'man',\n",
       " 'ran',\n",
       " 'fast',\n",
       " 'could',\n",
       " 'laughed',\n",
       " 'shouted',\n",
       " '--',\n",
       " '``',\n",
       " 'run',\n",
       " 'run',\n",
       " 'fast',\n",
       " '``',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " \"'m\",\n",
       " 'gingerbread',\n",
       " 'man',\n",
       " \"''\",\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'ran',\n",
       " 'came',\n",
       " 'cow',\n",
       " 'roadside',\n",
       " '``',\n",
       " 'stop',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'cow',\n",
       " '``',\n",
       " 'want',\n",
       " 'eat',\n",
       " \"''\",\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'laughed',\n",
       " 'said',\n",
       " '--',\n",
       " '``',\n",
       " 'run',\n",
       " 'away',\n",
       " 'little',\n",
       " 'old',\n",
       " 'woman',\n",
       " '``',\n",
       " 'little',\n",
       " 'old',\n",
       " 'man',\n",
       " '``',\n",
       " 'run',\n",
       " 'away',\n",
       " \"''\",\n",
       " 'cow',\n",
       " 'chased',\n",
       " 'looked',\n",
       " 'shoulder',\n",
       " 'cried',\n",
       " '--',\n",
       " '``',\n",
       " 'run',\n",
       " 'run',\n",
       " 'fast',\n",
       " '``',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " \"'m\",\n",
       " 'gingerbread',\n",
       " 'man',\n",
       " \"''\",\n",
       " 'cow',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'ran',\n",
       " 'till',\n",
       " 'came',\n",
       " 'horse',\n",
       " 'pasture',\n",
       " '``',\n",
       " 'please',\n",
       " 'stop',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " \"''\",\n",
       " 'said',\n",
       " 'horse',\n",
       " '``',\n",
       " 'look',\n",
       " 'good',\n",
       " 'eat',\n",
       " \"''\",\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'laughed',\n",
       " 'loud',\n",
       " '``',\n",
       " 'oho',\n",
       " 'oho',\n",
       " \"''\",\n",
       " 'said',\n",
       " '--',\n",
       " '``',\n",
       " 'run',\n",
       " 'away',\n",
       " 'little',\n",
       " 'old',\n",
       " 'woman',\n",
       " '``',\n",
       " 'little',\n",
       " 'old',\n",
       " 'man',\n",
       " '``',\n",
       " 'cow',\n",
       " '``',\n",
       " 'run',\n",
       " 'away',\n",
       " \"''\",\n",
       " 'horse',\n",
       " 'chased',\n",
       " 'looked',\n",
       " 'shoulder',\n",
       " 'cried',\n",
       " '--',\n",
       " '``',\n",
       " 'run',\n",
       " 'run',\n",
       " 'fast',\n",
       " '``',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " \"'m\",\n",
       " 'gingerbread',\n",
       " 'man',\n",
       " \"''\",\n",
       " 'horse',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'came',\n",
       " 'barn',\n",
       " 'full',\n",
       " 'threshers',\n",
       " 'threshers',\n",
       " 'smelt',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'tried',\n",
       " 'pick',\n",
       " 'said',\n",
       " '``',\n",
       " \"n't\",\n",
       " 'run',\n",
       " 'fast',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'look',\n",
       " 'good',\n",
       " 'eat',\n",
       " \"''\",\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'ran',\n",
       " 'harder',\n",
       " 'ever',\n",
       " 'ran',\n",
       " 'cried',\n",
       " '--',\n",
       " '``',\n",
       " 'run',\n",
       " 'away',\n",
       " 'little',\n",
       " 'old',\n",
       " 'woman',\n",
       " '``',\n",
       " 'little',\n",
       " 'old',\n",
       " 'man',\n",
       " '``',\n",
       " 'cow',\n",
       " '``',\n",
       " 'horse',\n",
       " '``',\n",
       " 'run',\n",
       " 'away',\n",
       " \"''\",\n",
       " 'found',\n",
       " 'ahead',\n",
       " 'threshers',\n",
       " 'turned',\n",
       " 'shouted',\n",
       " 'back',\n",
       " '--',\n",
       " '``',\n",
       " 'run',\n",
       " 'run',\n",
       " 'fast',\n",
       " '``',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " \"'m\",\n",
       " 'gingerbread',\n",
       " 'man',\n",
       " \"''\",\n",
       " 'threshers',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'catch',\n",
       " 'little',\n",
       " 'gingerbread',\n",
       " 'boy',\n",
       " 'ran',\n",
       " 'faster',\n",
       " 'ever',\n",
       " 'ran',\n",
       " 'ran',\n",
       " 'came',\n",
       " 'field',\n",
       " 'full',\n",
       " 'mowers',\n",
       " 'mowers',\n",
       " 'saw',\n",
       " 'fine',\n",
       " 'looked',\n",
       " 'ran',\n",
       " 'calling',\n",
       " '``',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_lowered_noStop_noPunc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09937fd7",
   "metadata": {},
   "source": [
    "## 3. Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23769b72",
   "metadata": {},
   "source": [
    "**Stemming** and **Lemmatization** are techniques used in natural language processing to reduce words to their base or root form, allowing different forms of the same word to be treated as one. For example: \"walks\", \"walking\", \"walked\" should all be the same as \"walk\".\n",
    "\n",
    "- **Stemming:**\n",
    "Stemming involves removing suffixes or prefixes from words to obtain their base form. The resulting stems might not always be actual words, but they represent the core meaning of the original words.\n",
    "\n",
    "- **Lemmatization:**\n",
    "Lemmatization, on the other hand, uses linguistic rules and knowledge to find the base or root word, which is called the lemma. Unlike stemming, lemmatization ensures that the resulting lemma is a valid word in the language. This requires the use of a lexicon or a vocabulary, as well as morphological analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f099899",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {\n",
    "        'NN':'n', \n",
    "        'JJ':'a',\n",
    "        'VB':'v', \n",
    "        'RB':'r'\n",
    "    }\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "    \n",
    "def lemmatize_sent(text): \n",
    "    return [\n",
    "        wnl.lemmatize(\n",
    "            word.lower(), \n",
    "            pos=penn2morphy(tag)\n",
    "        ) \n",
    "        for word, tag in pos_tag(word_tokenize(text))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7640d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        text: str - i.e. document/sentence\n",
    "    Output\n",
    "         list(str) - i.e. list of lemmas\n",
    "    \"\"\"\n",
    "    return [\n",
    "        word for word in lemmatize_sent(text) \n",
    "        if word not in stopwords_en_withpunct\n",
    "        and not word.isdigit()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed7f98",
   "metadata": {},
   "source": [
    "## 4. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "869c0b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts:\n",
      "Counter({'little': 11, '``': 9, \"''\": 8, 'say': 7, 'come': 6, 'tulip': 4, \"'s\": 3, 'want': 3, 'soft': 3, 'voice': 3, 'still': 2, 'hear': 2, '_tap': 2, 'tap': 2, 'tap_': 2, 'rain': 2, 'ca': 2, \"n't\": 2, 'whisper': 2, 'yellow': 1, 'live': 1, 'dark': 1, 'house': 1, 'ground': 1, 'one': 1, 'day': 1, 'sit': 1, 'suddenly': 1, 'door': 1, 'sad': 1, 'another': 1, 'window-pane': 1, 'answer': 1, 'long': 1, 'time': 1, 'last': 1, 'rustling': 1, 'sound': 1, 'round': 1, 'window': 1, '_rustle': 1, 'whisper_': 1, 'sunshine': 1, 'cheery': 1})\n"
     ]
    }
   ],
   "source": [
    "processed_sent = preprocess_text(text)\n",
    "\n",
    "print('Word counts:')\n",
    "print(Counter(processed_sent[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197b8fa",
   "metadata": {},
   "source": [
    "## 5. Tweeter Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d0e0f",
   "metadata": {},
   "source": [
    "In this section, we will use dataset from this link https://www.kaggle.com/code/pavansanagapati/knowledge-graph-nlp-tutorial-bert-spacy-nltk/data to identify which Tweets are about disaster and which ones are not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5240c1b",
   "metadata": {},
   "source": [
    "`Training data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb4c3365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and read csv file\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Create Train dataset with 3 columns (id, text, target)\n",
    "df_train = df[['id', 'text', 'target']]\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea399c2",
   "metadata": {},
   "source": [
    "`Testing data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd2ec35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0                 Just happened a terrible car crash\n",
       "1   2  Heard about #earthquake is different cities, s...\n",
       "2   3  there is a forest fire at spot pond, geese are...\n",
       "3   9           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and read csv file\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Create Train dataset with 2 columns (id, text)\n",
    "df_test = df[['id', 'text']]\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "410a9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation split, with test size of 25%\n",
    "train, valid = train_test_split(df_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8eaaf8",
   "metadata": {},
   "source": [
    "## 6. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7feb2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer and \n",
    "# override the analyzer totally with the preprocess_text().\n",
    "count_vect = CountVectorizer(\n",
    "    analyzer=preprocess_text\n",
    ")\n",
    "\n",
    "# When we use `CounterVectorizer.fit_transform`,\n",
    "# we essentially create the dictionary and \n",
    "# vectorize our input text at the same time.\n",
    "train_set = count_vect.fit_transform(train['text'])\n",
    "train_tags = train['target']\n",
    "\n",
    "# When vectorizing the validation data and testing data, we use `CountVectorizer.transform()`.\n",
    "valid_set = count_vect.transform(valid['text'])\n",
    "valid_tags = valid['target']\n",
    "\n",
    "test_set = count_vect.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345af3e",
   "metadata": {},
   "source": [
    "## 7. Modelling: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba063376",
   "metadata": {},
   "source": [
    "In this section, we will focus on building a binary classification model using Naive Bayes to determine whether a tweet is related to a disaster or not. The process involves training the model on a training set and evaluating its performance on a validation set using 5-fold cross-validation. After fine-tuning the model, we will train it on the full training set and predict on a hold-out (test set) to assess its overall effectiveness in classifying disaster-related tweets accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83791709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean Performace of Naive Bayes classifier model =  0.7962863251733279\n",
      "The standard deviation Performace of Naive Bayes classifier model =  0.015196153672174995\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "\n",
    "# To train the classifier, simple do \n",
    "clf.fit(train_set, train_tags) \n",
    "\n",
    "# Add 5-fold cross-validation to the train set and calculate the mean and standard deviation of the performance\n",
    "score = cross_validate(clf, train_set, train_tags, cv=5)\n",
    "print(\"The mean Performace of Naive Bayes classifier model = \", np.mean(score['test_score']))\n",
    "print(\"The standard deviation Performace of Naive Bayes classifier model = \", np.std(score['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab2496d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disaster prediction from tweet accuracy = 79.56932773109243\n"
     ]
    }
   ],
   "source": [
    "# To predict our tags (i.e. whether requesters get their pizza), \n",
    "# we feed the vectorized `test_set` to .predict()\n",
    "predictions_valid = clf.predict(valid_set)\n",
    "\n",
    "print('Disaster prediction from tweet accuracy = {}'.format(\n",
    "        accuracy_score(predictions_valid, valid_tags) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682cb77",
   "metadata": {},
   "source": [
    "Re-vectorize the train and test set since now our vectorizer is different using the full training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6b3a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(\n",
    "    analyzer=preprocess_text\n",
    ")\n",
    "\n",
    "full_train_set = count_vect.fit_transform(df_train['text'])\n",
    "full_tags = df_train['target']\n",
    "\n",
    "test_set = count_vect.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbce6c7",
   "metadata": {},
   "source": [
    "Now, train with full data set (Train data + Validation Data) and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f54a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(full_train_set, full_tags) \n",
    "predictions = clf.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b6bca",
   "metadata": {},
   "source": [
    "## 8. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d68d37d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>They'd probably still show more life than Arse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>What a nice hat?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>Fuck off!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  prediction\n",
       "0   0                 Just happened a terrible car crash           1\n",
       "1   2  Heard about #earthquake is different cities, s...           1\n",
       "2   3  there is a forest fire at spot pond, geese are...           1\n",
       "3   9           Apocalypse lighting. #Spokane #wildfires           1\n",
       "4  11      Typhoon Soudelor kills 28 in China and Taiwan           1\n",
       "5  12                 We're shaking...It's an earthquake           1\n",
       "6  21  They'd probably still show more life than Arse...           0\n",
       "7  22                                  Hey! How are you?           0\n",
       "8  27                                   What a nice hat?           0\n",
       "9  29                                          Fuck off!           0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"prediction\"] = predictions\n",
    "\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdce90c",
   "metadata": {},
   "source": [
    "Upon examining the initial 10 rows of Twitter data, it becomes evident that our Naive Bayes model has the capability to predict whether a post is associated with a disaster or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2720f1",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42ae23",
   "metadata": {},
   "source": [
    "In this project, we successfully developed a disaster prediction model using tweets and natural language processing techniques. The model achieved an accuracy of 79.57% in classifying tweets as disaster-related or non-disaster-related, demonstrating its capability to discern relevant information during emergencies.\n",
    "\n",
    "Our journey began by preprocessing the Twitter data, including tokenization and feature extraction. We leveraged the power of Naive Bayes, a simple yet effective machine learning algorithm, to perform binary classification. The model's accuracy suggests that it can aid emergency responders, news agencies, and the public in quickly identifying disaster-related tweets amidst the vast volume of social media content.\n",
    "\n",
    "While the achieved accuracy is commendable, there is always room for further improvement. Future work may involve exploring advanced deep learning models or incorporating domain-specific lexicons to enhance sentiment analysis. Additionally, considering contextual factors and the evolving nature of language in tweets could lead to better generalization and higher accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
